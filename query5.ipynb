{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f11ef27-081c-4b4a-bc87-72bbde087481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '2', 'spark.executor.memory': '8g', 'spark.executor.cores': '4'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1644</td><td>application_1765289937462_1629</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1629/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-61.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1629_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1647</td><td>application_1765289937462_1632</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1632/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-131.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1632_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1654</td><td>application_1765289937462_1638</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1638/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1638_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1667</td><td>application_1765289937462_1651</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1651/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-55.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1651_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1671</td><td>application_1765289937462_1655</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1655/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-103.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1655_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1673</td><td>None</td><td>pyspark</td><td>starting</td><td></td><td></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.executor.instances\": \"2\",\n",
    "        \"spark.executor.memory\": \"8g\",\n",
    "        \"spark.executor.cores\": \"4\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff6718c-b922-4f0d-9b8c-6893fa6c62bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '4', 'spark.executor.memory': '4g', 'spark.executor.cores': '2'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1644</td><td>application_1765289937462_1629</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1629/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-61.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1629_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1647</td><td>application_1765289937462_1632</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1632/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-131.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1632_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1654</td><td>application_1765289937462_1638</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1638/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1638_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1667</td><td>application_1765289937462_1651</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1651/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-55.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1651_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1671</td><td>application_1765289937462_1655</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1655/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-103.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1655_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1673</td><td>application_1765289937462_1657</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1657/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-55.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1657_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1675</td><td>application_1765289937462_1659</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1659/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-154.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1659_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.executor.instances\": \"4\",\n",
    "        \"spark.executor.memory\": \"4g\",\n",
    "        \"spark.executor.cores\": \"2\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec433cd8-54f0-45a2-b42d-d9a699cd0ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '8', 'spark.executor.memory': '2g', 'spark.executor.cores': '1'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1644</td><td>application_1765289937462_1629</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1629/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-61.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1629_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1667</td><td>application_1765289937462_1651</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1651/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-55.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1651_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1673</td><td>application_1765289937462_1657</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1657/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-55.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1657_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1680</td><td>application_1765289937462_1664</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1664/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-103.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1664_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1681</td><td>application_1765289937462_1665</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1665/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1665_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1682</td><td>application_1765289937462_1666</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1666/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-141.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1666_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1686</td><td>application_1765289937462_1670</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1670/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-154.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1670_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1687</td><td>application_1765289937462_1671</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1671/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-213.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1671_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.executor.instances\": \"8\",\n",
    "        \"spark.executor.memory\": \"2g\",\n",
    "        \"spark.executor.cores\": \"1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "128cab82-d9e2-4ffe-80c3-2ae89a9ecba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1688</td><td>application_1765289937462_1672</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1672/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-149.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1672_01_000002/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db66d3f5463423199eec3dbd9e4ef1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe0e7441cc340faa8c1cf4a45583c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, DoubleType\n",
    "from sedona.spark import *\n",
    "import json\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, count, desc, split, avg, row_number, year, to_timestamp, expr, lit, to_date, regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7a57f6-4928-49db-978b-5faeca1a2259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a0745f61da47bd82ed4040831675f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CRIMES_PATH = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\"\n",
    "CENSUS_PATH = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Census_Blocks_2020.geojson\"\n",
    "INCOME_PATH = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_income_2021.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d84f76ab-bf35-4b11-bd64-8f8e9ca02a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da62b243656a440fac89e9ce55bc39d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Final Rows: 154\n",
      "\n",
      "--- Final Data Sample (Per Capita) ---\n",
      "+--------------------+------------------+--------------------+\n",
      "|                COMM| per_capita_income|          crime_rate|\n",
      "+--------------------+------------------+--------------------+\n",
      "|Rosewood/East Gar...| 16560.82904884319|0.011568123393316195|\n",
      "|      Toluca Terrace|25786.809278350516|0.017304860088365244|\n",
      "|        Elysian Park|26141.354852410277| 0.07825440645572308|\n",
      "|            Longwood|20725.211884284596|0.048605681522022416|\n",
      "|       Green Meadows| 11848.86150789897| 0.07541859805127235|\n",
      "+--------------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Global Correlation (Per Capita vs Crime Rate): -0.1676344553502217\n",
      "\n",
      "--- Top 10 Per Capita Income Areas ---\n",
      "+-------------------+-----------------+--------------------+\n",
      "|               COMM|per_capita_income|          crime_rate|\n",
      "+-------------------+-----------------+--------------------+\n",
      "|     Marina del Rey| 97983.0745900194|0.002953623699523...|\n",
      "|  Pacific Palisades|87750.52529591447|  0.0325028636884307|\n",
      "|   Marina Peninsula|85588.53457067102| 0.04813379563532531|\n",
      "|Palisades Highlands|83576.88954231654|0.016236256711838405|\n",
      "|        Playa Vista|81679.88040665434| 0.03986444855206408|\n",
      "|            Bel Air|80412.74199793495|0.034073309241094474|\n",
      "|          Brentwood| 72946.3541900178| 0.03535636579415837|\n",
      "|      Beverly Crest|69669.54254069475| 0.02584326229233093|\n",
      "|  Mandeville Canyon| 65870.0709438618|0.015885256014805674|\n",
      "|             Venice| 63440.7489833752| 0.09442650400669776|\n",
      "+-------------------+-----------------+--------------------+\n",
      "\n",
      "Top 10 Corr: -0.5005562422035678\n",
      "\n",
      "--- Bottom 10 Per Capita Income Areas ---\n",
      "+------------------+------------------+--------------------+\n",
      "|              COMM| per_capita_income|          crime_rate|\n",
      "+------------------+------------------+--------------------+\n",
      "|    Vernon Central|10950.147886890725| 0.04510222076404126|\n",
      "|        South Park|11413.401021995112| 0.05468229282381693|\n",
      "|           Central|11541.450975876562| 0.04921123841326501|\n",
      "|             Watts|11751.343251432088|  0.0565970742792217|\n",
      "|     Green Meadows| 11848.86150789897| 0.07541859805127235|\n",
      "|Florence-Firestone| 12294.28150086774|0.029716661562305687|\n",
      "|   University Park|12374.622544283415| 0.07228260869565217|\n",
      "|     Vermont Vista|12434.680719125847| 0.08552746730677868|\n",
      "|Century Palms/Cove|12635.488322977564| 0.07679593523308133|\n",
      "|    Vermont Square|13262.203166226913| 0.04538258575197889|\n",
      "+------------------+------------------+--------------------+\n",
      "\n",
      "Bottom 10 Corr: 0.20103891349035236\n",
      "Total Execution Time: 55.66944622993469 seconds"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Query 5\").getOrCreate()\n",
    "sedona = SedonaContext.create(spark)\n",
    "\n",
    "def load_crime_data(path):\n",
    "    df = spark.read.csv(path, header=True)\n",
    "    df = df.select(\"LAT\", \"LON\", \"DATE OCC\")\n",
    "    df = df.withColumn(\"LAT\", F.col(\"LAT\").cast(\"float\")) \\\n",
    "           .withColumn(\"LON\", F.col(\"LON\").cast(\"float\")) \\\n",
    "           .filter((F.col(\"LAT\") != 0) & (F.col(\"LON\") != 0)) \\\n",
    "           .filter(F.col(\"LAT\").isNotNull() & F.col(\"LON\").isNotNull())\n",
    "  \n",
    "    df = df.withColumn(\"ts_occ\", F.to_timestamp(F.col(\"DATE OCC\"), \"yyyy MMM dd hh:mm:ss a\")) \\\n",
    "           .withColumn(\"year\", F.year(\"ts_occ\")) \\\n",
    "           .filter(F.col(\"year\").isin([2020, 2021]))\n",
    "    \n",
    "    return df.withColumn(\"geom\", F.expr(\"ST_Point(LON, LAT)\"))\n",
    "\n",
    "def load_census_full(path):\n",
    "\n",
    "    df = sedona.read.format(\"geojson\").option(\"multiLine\", \"true\").load(path)\n",
    "    \n",
    "    df = df.selectExpr(\"explode(features) as feature\") \\\n",
    "           .select(\n",
    "               F.col(\"feature.properties.COMM\").alias(\"COMM\"),\n",
    "               F.col(\"feature.properties.POP20\").cast(\"long\").alias(\"POP20\"),\n",
    "               F.col(\"feature.properties.HOUSING20\").cast(\"long\").alias(\"HOUSING20\"),  # arithmos noikokyriwn\n",
    "               F.col(\"feature.properties.ZCTA20\").alias(\"ZCTA20\"),\n",
    "               F.col(\"feature.geometry\").alias(\"geometry\")\n",
    "           )\n",
    "\n",
    "    return df.filter(F.col(\"geometry\").isNotNull())\n",
    "\n",
    "def load_income(path):\n",
    "    df = spark.read.option(\"delimiter\", \";\").option(\"header\", \"true\").csv(path)\n",
    "    df = df.select(\"Estimated Median Income\", \"Zip Code\")\n",
    "    return df.withColumn(\"income_cleaned\", F.regexp_replace(F.col(\"Estimated Median Income\"), \"[$,]\", \"\")) \\\n",
    "             .withColumn(\"median_income\", F.col(\"income_cleaned\").cast(\"double\")) \\\n",
    "             .withColumn(\"Zip Code\", F.trim(F.col(\"Zip Code\")))\n",
    "\n",
    "crimes = load_crime_data(CRIMES_PATH)\n",
    "census = load_census_full(CENSUS_PATH)\n",
    "income = load_income(INCOME_PATH)\n",
    "\n",
    "start_time = time.time()\n",
    "# spatial join crimes x census\n",
    "# Se poia perioxh anhkei kathe egklhma\n",
    "crimes_geo = crimes.alias(\"c\").join(\n",
    "    F.broadcast(census.alias(\"b\")),\n",
    "    F.expr(\"ST_Contains(b.geometry, c.geom)\")\n",
    ").select(F.col(\"b.COMM\").alias(\"community\"))\n",
    "\n",
    "# count crimes per area\n",
    "crime_counts = crimes_geo.groupBy(\"community\").agg(F.count(\"*\").alias(\"total_crimes\"))\n",
    "\n",
    "# join census x income (Zip Code)\n",
    "# se kathe block antistoixei to median household income\n",
    "census_prep = census.withColumn(\"ZCTA20\", F.trim(F.col(\"ZCTA20\")))\n",
    "census_income = census_prep.join(income, census_prep[\"ZCTA20\"] == income[\"Zip Code\"])\n",
    "\n",
    "# synoliko eisodhma block\n",
    "# total block income = median household income * arithmos noikokyriwn \n",
    "census_income = census_income.withColumn(\n",
    "    \"block_total_income\", \n",
    "    F.col(\"median_income\") * F.col(\"HOUSING20\")\n",
    ")\n",
    "# ana perioxh\n",
    "# athroizw pop kai total block income ana perioxh\n",
    "comm_stats = census_income.groupBy(\"COMM\").agg(\n",
    "    F.sum(\"POP20\").alias(\"total_pop\"),\n",
    "    F.sum(\"block_total_income\").alias(\"total_income_area\")\n",
    ")\n",
    "\n",
    "# kata kefalhn eisodhma perioxhs = total income perioxhs / total pop perioxhs\n",
    "comm_stats = comm_stats.withColumn(\n",
    "    \"per_capita_income\", \n",
    "    F.col(\"total_income_area\") / F.col(\"total_pop\")\n",
    ")\n",
    "\n",
    "# join crime counts x comm stats\n",
    "final_df = crime_counts.join(comm_stats, F.col(\"community\") == F.col(\"COMM\")) \\\n",
    "                       .drop(\"community\")\n",
    "\n",
    "# ethsia mesh analogia egklhmatwn ana atomo ana perioxh\n",
    "final_df = final_df.withColumn(\"crime_rate\", (F.col(\"total_crimes\") / 2) / F.col(\"total_pop\"))\n",
    "\n",
    "final_df = final_df.filter(\n",
    "    (F.col(\"total_pop\") > 0) & \n",
    "    (F.col(\"per_capita_income\").isNotNull()) & \n",
    "    (F.col(\"per_capita_income\") > 0)\n",
    ")\n",
    "\n",
    "final_df.cache()\n",
    "print(f\"--> Final Rows: {final_df.count()}\")\n",
    "\n",
    "if final_df.count() > 0:\n",
    "    print(\"\\n--- Final Data Sample (Per Capita) ---\")\n",
    "    final_df.select(\"COMM\", \"per_capita_income\", \"crime_rate\").show(5)\n",
    "\n",
    "    # global corr\n",
    "    print(f\"Global Correlation (Per Capita vs Crime Rate): {final_df.stat.corr('per_capita_income', 'crime_rate')}\")\n",
    "\n",
    "    # top 10 income perioxes\n",
    "    print(\"\\n--- Top 10 Per Capita Income Areas ---\")\n",
    "    top10 = final_df.orderBy(F.col(\"per_capita_income\").desc()).limit(10)\n",
    "    top10.select(\"COMM\", \"per_capita_income\", \"crime_rate\").show()\n",
    "    print(f\"Top 10 Corr: {top10.stat.corr('per_capita_income', 'crime_rate')}\")\n",
    "\n",
    "    # bottom 10 income perioxes\n",
    "    print(\"\\n--- Bottom 10 Per Capita Income Areas ---\")\n",
    "    bot10 = final_df.orderBy(F.col(\"per_capita_income\").asc()).limit(10)\n",
    "    bot10.select(\"COMM\", \"per_capita_income\", \"crime_rate\").show()\n",
    "    print(f\"Bottom 10 Corr: {bot10.stat.corr('per_capita_income', 'crime_rate')}\")\n",
    "else:\n",
    "    print(\"!!! ERROR: Table is empty. !!!\")\n",
    "\n",
    "end_time = time.time()  \n",
    "\n",
    "execution_duration = end_time - start_time\n",
    "print(f\"Total Execution Time: {execution_duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7f5e83-9970-4dff-b046-47a50969f5ec",
   "metadata": {},
   "source": [
    "| Category | Correlation Value |\n",
    "| :--- | :--- |\n",
    "| Global Correlation | -0.16763445535022178 |\n",
    "| Top 10 Income Areas | -0.5005562422035678 |\n",
    "| Bottom 10 Income Areas | 0.20103891349035236 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d9d8c5-1607-4e3f-9d5e-0a8ab1cf1270",
   "metadata": {},
   "source": [
    "| Configuration | Execution Time (s) |\n",
    "| :--- | :--- |\n",
    "| 4 cores, 8GB mem | 49.2229700088501 |\n",
    "| 2 cores, 4GB mem | 54.48193287849426 |\n",
    "| 1 cores, 2GB mem | 55.66944622993469 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04088091-0556-4069-91c8-a68c8fe32a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a0cc457a5b4a058ee0839178cd16d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- InMemoryTableScan [total_crimes#222L, COMM#140, total_pop#271L, total_income_area#273, per_capita_income#277, crime_rate#304]\n",
      "      +- InMemoryRelation [total_crimes#222L, COMM#140, total_pop#271L, total_income_area#273, per_capita_income#277, crime_rate#304], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "            +- AdaptiveSparkPlan isFinalPlan=true\n",
      "               +- == Final Plan ==\n",
      "                  *(6) Project [total_crimes#222L, COMM#140, total_pop#271L, total_income_area#273, per_capita_income#277, ((cast(total_crimes#222L as double) / 2.0) / cast(total_pop#271L as double)) AS crime_rate#304]\n",
      "                  +- *(6) BroadcastHashJoin [community#218], [COMM#140], Inner, BuildRight, false\n",
      "                     :- *(6) HashAggregate(keys=[community#218], functions=[count(1)], schema specialized)\n",
      "                     :  +- ShuffleQueryStage 0\n",
      "                     :     +- Exchange hashpartitioning(community#218, 1000), ENSURE_REQUIREMENTS, [plan_id=388]\n",
      "                     :        +- *(2) HashAggregate(keys=[community#218], functions=[partial_count(1)], schema specialized)\n",
      "                     :           +- *(2) Filter true\n",
      "                     :              +- *(2) Project [COMM#140 AS community#218]\n",
      "                     :                 +- BroadcastIndexJoin geom#121: geometry, RightSide, RightSide, Inner, CONTAINS ST_CONTAINS(geometry#144, geom#121)\n",
      "                     :                    :- Project [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#121]\n",
      "                     :                    :  +- Filter (((((isnotnull(LAT#68) AND isnotnull(LON#69)) AND NOT (cast(LAT#68 as float) = 0.0)) AND NOT (cast(LON#69 as float) = 0.0)) AND year(cast(gettimestamp(DATE OCC#44, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) IN (2020,2021)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "                     :                    :     +- FileScan csv [DATE OCC#44,LAT#68,LON#69] Batched: false, DataFilters: [isnotnull(LAT#68), isnotnull(LON#69), NOT (cast(LAT#68 as float) = 0.0), NOT (cast(LON#69 as flo..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON)], ReadSchema: struct<DATE OCC:string,LAT:string,LON:string>\n",
      "                     :                    +- SpatialIndex geometry#144: geometry, RTREE, false, false\n",
      "                     :                       +- *(1) Project [feature#137.properties.COMM AS COMM#140, feature#137.geometry AS geometry#144]\n",
      "                     :                          +- *(1) Filter (isnotnull(feature#137.geometry) AND isnotnull(feature#137.properties.COMM))\n",
      "                     :                             +- *(1) Generate explode(features#129), false, [feature#137]\n",
      "                     :                                +- *(1) Filter ((size(features#129, true) > 0) AND isnotnull(features#129))\n",
      "                     :                                   +- FileScan geojson [features#129] Batched: false, DataFilters: [(size(features#129, true) > 0), isnotnull(features#129)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string...\n",
      "                     +- BroadcastQueryStage 3\n",
      "                        +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=621]\n",
      "                           +- *(5) Project [COMM#140, total_pop#271L, total_income_area#273, (total_income_area#273 / cast(total_pop#271L as double)) AS per_capita_income#277]\n",
      "                              +- *(5) Filter ((((isnotnull(total_pop#271L) AND isnotnull(total_income_area#273)) AND (total_pop#271L > 0)) AND isnotnull((total_income_area#273 / cast(total_pop#271L as double)))) AND ((total_income_area#273 / cast(total_pop#271L as double)) > 0.0))\n",
      "                                 +- *(5) HashAggregate(keys=[COMM#140], functions=[sum(POP20#141L), sum(block_total_income#249)], schema specialized)\n",
      "                                    +- AQEShuffleRead coalesced\n",
      "                                       +- ShuffleQueryStage 2\n",
      "                                          +- Exchange hashpartitioning(COMM#140, 1000), ENSURE_REQUIREMENTS, [plan_id=531]\n",
      "                                             +- *(4) HashAggregate(keys=[COMM#140], functions=[partial_sum(POP20#141L), partial_sum(block_total_income#249)], schema specialized)\n",
      "                                                +- *(4) Project [COMM#140, POP20#141L, (median_income#186 * cast(HOUSING20#142L as double)) AS block_total_income#249]\n",
      "                                                   +- *(4) BroadcastHashJoin [ZCTA20#225], [Zip Code#191], Inner, BuildRight, false\n",
      "                                                      :- *(4) Project [feature#137.properties.COMM AS COMM#140, feature#137.properties.POP20 AS POP20#141L, feature#137.properties.HOUSING20 AS HOUSING20#142L, trim(feature#137.properties.ZCTA20, None) AS ZCTA20#225]\n",
      "                                                      :  +- *(4) Filter ((isnotnull(feature#137.geometry) AND isnotnull(trim(feature#137.properties.ZCTA20, None))) AND isnotnull(feature#137.properties.COMM))\n",
      "                                                      :     +- *(4) Generate explode(features#283), false, [feature#137]\n",
      "                                                      :        +- *(4) Filter ((size(features#283, true) > 0) AND isnotnull(features#283))\n",
      "                                                      :           +- FileScan geojson [features#283] Batched: false, DataFilters: [(size(features#283, true) > 0), isnotnull(features#283)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string...\n",
      "                                                      +- BroadcastQueryStage 1\n",
      "                                                         +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=419]\n",
      "                                                            +- *(3) Project [trim(Zip Code#173, None) AS Zip Code#191, cast(regexp_replace(Estimated Median Income#175, [$,], , 1) as double) AS median_income#186]\n",
      "                                                               +- *(3) Filter isnotnull(trim(Zip Code#173, None))\n",
      "                                                                  +- FileScan csv [Zip Code#173,Estimated Median Income#175] Batched: false, DataFilters: [isnotnull(trim(Zip Code#173, None))], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_i..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Zip Code:string,Estimated Median Income:string>\n",
      "               +- == Initial Plan ==\n",
      "                  Project [total_crimes#222L, COMM#140, total_pop#271L, total_income_area#273, per_capita_income#277, ((cast(total_crimes#222L as double) / 2.0) / cast(total_pop#271L as double)) AS crime_rate#304]\n",
      "                  +- SortMergeJoin [community#218], [COMM#140], Inner\n",
      "                     :- Sort [community#218 ASC NULLS FIRST], false, 0\n",
      "                     :  +- HashAggregate(keys=[community#218], functions=[count(1)], schema specialized)\n",
      "                     :     +- Exchange hashpartitioning(community#218, 1000), ENSURE_REQUIREMENTS, [plan_id=320]\n",
      "                     :        +- HashAggregate(keys=[community#218], functions=[partial_count(1)], schema specialized)\n",
      "                     :           +- Filter true\n",
      "                     :              +- Project [COMM#140 AS community#218]\n",
      "                     :                 +- BroadcastIndexJoin geom#121: geometry, RightSide, RightSide, Inner, CONTAINS ST_CONTAINS(geometry#144, geom#121)\n",
      "                     :                    :- Project [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#121]\n",
      "                     :                    :  +- Filter (((((isnotnull(LAT#68) AND isnotnull(LON#69)) AND NOT (cast(LAT#68 as float) = 0.0)) AND NOT (cast(LON#69 as float) = 0.0)) AND year(cast(gettimestamp(DATE OCC#44, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) IN (2020,2021)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "                     :                    :     +- FileScan csv [DATE OCC#44,LAT#68,LON#69] Batched: false, DataFilters: [isnotnull(LAT#68), isnotnull(LON#69), NOT (cast(LAT#68 as float) = 0.0), NOT (cast(LON#69 as flo..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON)], ReadSchema: struct<DATE OCC:string,LAT:string,LON:string>\n",
      "                     :                    +- SpatialIndex geometry#144: geometry, RTREE, false, false\n",
      "                     :                       +- Project [feature#137.properties.COMM AS COMM#140, feature#137.geometry AS geometry#144]\n",
      "                     :                          +- Filter (isnotnull(feature#137.geometry) AND isnotnull(feature#137.properties.COMM))\n",
      "                     :                             +- Generate explode(features#129), false, [feature#137]\n",
      "                     :                                +- Filter ((size(features#129, true) > 0) AND isnotnull(features#129))\n",
      "                     :                                   +- FileScan geojson [features#129] Batched: false, DataFilters: [(size(features#129, true) > 0), isnotnull(features#129)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string...\n",
      "                     +- Sort [COMM#140 ASC NULLS FIRST], false, 0\n",
      "                        +- Project [COMM#140, total_pop#271L, total_income_area#273, (total_income_area#273 / cast(total_pop#271L as double)) AS per_capita_income#277]\n",
      "                           +- Filter ((((isnotnull(total_pop#271L) AND isnotnull(total_income_area#273)) AND (total_pop#271L > 0)) AND isnotnull((total_income_area#273 / cast(total_pop#271L as double)))) AND ((total_income_area#273 / cast(total_pop#271L as double)) > 0.0))\n",
      "                              +- HashAggregate(keys=[COMM#140], functions=[sum(POP20#141L), sum(block_total_income#249)], schema specialized)\n",
      "                                 +- Exchange hashpartitioning(COMM#140, 1000), ENSURE_REQUIREMENTS, [plan_id=253]\n",
      "                                    +- HashAggregate(keys=[COMM#140], functions=[partial_sum(POP20#141L), partial_sum(block_total_income#249)], schema specialized)\n",
      "                                       +- Project [COMM#140, POP20#141L, (median_income#186 * cast(HOUSING20#142L as double)) AS block_total_income#249]\n",
      "                                          +- BroadcastHashJoin [ZCTA20#225], [Zip Code#191], Inner, BuildRight, false\n",
      "                                             :- Project [feature#137.properties.COMM AS COMM#140, feature#137.properties.POP20 AS POP20#141L, feature#137.properties.HOUSING20 AS HOUSING20#142L, trim(feature#137.properties.ZCTA20, None) AS ZCTA20#225]\n",
      "                                             :  +- Filter ((isnotnull(feature#137.geometry) AND isnotnull(trim(feature#137.properties.ZCTA20, None))) AND isnotnull(feature#137.properties.COMM))\n",
      "                                             :     +- Generate explode(features#283), false, [feature#137]\n",
      "                                             :        +- Filter ((size(features#283, true) > 0) AND isnotnull(features#283))\n",
      "                                             :           +- FileScan geojson [features#283] Batched: false, DataFilters: [(size(features#283, true) > 0), isnotnull(features#283)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string...\n",
      "                                             +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=248]\n",
      "                                                +- Project [trim(Zip Code#173, None) AS Zip Code#191, cast(regexp_replace(Estimated Median Income#175, [$,], , 1) as double) AS median_income#186]\n",
      "                                                   +- Filter isnotnull(trim(Zip Code#173, None))\n",
      "                                                      +- FileScan csv [Zip Code#173,Estimated Median Income#175] Batched: false, DataFilters: [isnotnull(trim(Zip Code#173, None))], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_i..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Zip Code:string,Estimated Median Income:string>"
     ]
    }
   ],
   "source": [
    "final_df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7bc9c2-70cf-4112-b13b-8ac72efec717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
